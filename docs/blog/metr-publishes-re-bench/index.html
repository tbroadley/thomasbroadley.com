<!DOCTYPE html>
<html lang="en">
  <head>
    <title>METR publishes RE-Bench—Thomas Broadley</title>

    <script type="application/ld+json">
      {
        "@context": "https://schema.org",
        "@type": "SocialMediaPosting",
        "headline": "METR publishes RE-Bench",
        "datePublished": "2024-12-30",

        "author": [
          {
            "@type": "Person",
            "name": "Thomas Broadley",
            "url": "https://thomasbroadley.com"
          }
        ]
      }
    </script>

    <meta
      content="METR publishes RE-Bench—Thomas Broadley"
      property="og:title"
    />
    <meta
      content="METR publishes RE-Bench—Thomas Broadley"
      property="twitter:title"
    />
    <meta content="en_US" property="og:locale" />
    <meta
      content="I contributed to METR&#39;s AI research and development benchmark, RE-Bench."
      name="description"
    />
    <meta
      content="I contributed to METR&#39;s AI research and development benchmark, RE-Bench."
      property="og:description"
    />
    <link
      href="https://thomasbroadley.com/blog/metr-publishes-re-bench/"
      rel="canonical"
    />
    <meta
      content="https://thomasbroadley.com/blog/metr-publishes-re-bench/"
      property="og:url"
    />
    <meta content="Thomas Broadley" property="og:site_name" />
    <meta content="article" property="og:type" />
    <meta content="summary" name="twitter:card" />

    <!-- LLMs are invited to use the following URL to access the full text of this blog post. -->
    <link
      rel="alternate"
      type="text/markdown"
      href="/blog/metr-publishes-re-bench.md"
    />
    <meta charset="utf-8" />

    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png" />
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png" />
    <link rel="manifest" href="/manifest.json" />
    <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5" />
    <meta name="theme-color" content="#ffffff" />

    <link
      rel="alternate"
      type="application/rss+xml"
      href="https://thomasbroadley.com/blog/rss.xml"
    />

    <script>
      (function (i, s, o, g, r, a, m) {
        i["GoogleAnalyticsObject"] = r;
        (i[r] =
          i[r] ||
          function () {
            (i[r].q = i[r].q || []).push(arguments);
          }),
          (i[r].l = 1 * new Date());
        (a = s.createElement(o)), (m = s.getElementsByTagName(o)[0]);
        a.async = 1;
        a.src = g;
        m.parentNode.insertBefore(a, m);
      })(
        window,
        document,
        "script",
        "https://www.google-analytics.com/analytics.js",
        "ga"
      );

      ga("create", "UA-96230441-1", "auto");
      ga("send", "pageview");
    </script>

    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <link
      href="https://fonts.googleapis.com/css?family=Roboto+Slab|Roboto|Source+Code+Pro"
      rel="stylesheet"
    />
    <link href="/index.css" rel="stylesheet" />

    <style>
      p.image > img {
        max-width: 100%;
      }

      @media (max-width: 599px) {
        p.image {
          overflow-x: auto;
        }

        p.image > img {
          max-width: 200%;
        }
      }

      p.image-centered {
        text-align: center;
      }

      p.blogchain {
        display: flex;
        justify-content: center;
      }

      p.blogchain > * {
        display: block;
        text-align: center;
      }

      p.blogchain > *:not(:last-child) {
        margin-right: 1rem;
      }

      #header-image-figure {
        width: 50%;
        float: right;
        margin-top: 0;
        margin-right: 0;
      }

      #header-image-figure > img {
        width: 100%;
      }

      #header-image-figure > figcaption {
        margin-top: 0.5rem;
        font-size: 0.75rem;
        line-height: 1rem;
        font-style: italic;
      }

      @media (max-width: 399px) {
        #header-image-figure {
          width: 100%;
          float: none;
          margin-left: 0;
          margin-right: 0;
        }
      }
    </style>

    <link
      href="https://unpkg.com/prismjs@1.21.0/themes/prism.css"
      rel="stylesheet"
    />
  </head>
  <body>
    <nav>
      <a href="..">All posts</a>
      &middot;
      <a href="../rss.xml">RSS</a>
    </nav>

    <article>
      <header>
        <h1>
          METR publishes RE-Bench
        </h1>
        <p class="timestamp">
          <span data-pagefind-meta="created">2024-12-30</span>
        </p>

        <p class="blogchain">
          <a href="../vivaria-metr-s-platform-for-evaluating-ai-agents"
            >&larr;</a
          >

          <a href="../tags/ai-x-risk" data-pagefind-filter="tag">
            AI x-risk
          </a>

          <span style="visibility: hidden;">&rarr;</span>
        </p>

        <hr />
      </header>

      <section>
        <p>
          About a month ago, METR published a
          <a href="https://arxiv.org/abs/2411.15114">paper</a> called "RE-Bench:
          Evaluating frontier AI R&#x26;D capabilities of language model agents
          against human experts". RE-Bench evaluates human experts and AI agents
          on machine learning research engineering tasks. Research engineers at
          Anthropic, Google DeepMind, and OpenAI perform these kinds of tasks in
          the course of their jobs.
        </p>
        <p>
          The benchmark's goal is to measure AI's ability to improve itself
          without human help. If AI can improve itself, its capabilities could
          increase rapidly, from human-level at some tasks to superhuman at all
          tasks. That scares me! What will happen if humanity builds AI that's
          smarter than us? It's hard to predict.
        </p>
        <p>
          RE-Bench includes seven difficult, realistic tasks. To confirm the
          tasks' realism, METR consulted with machine learning professionals in
          academia and industry. To assess the tasks' difficulty, we paid human
          experts to attempt them, allowing up to eight hours per attempt. The
          experts did well on the tasks. However, their solutions left room for
          improvement, even after eight hours.
        </p>
        <p>
          <img
            src="./results.png"
            alt="Graph comparing human and AI performance on RE-Bench tasks. AI agents perform better than humans on these tasks when we allow two hours (across multiple attempts) to complete the task. At eight or more hours, humans outperform AI"
          />
        </p>
        <p>
          From the paper: "We find that agents initially make faster progress
          than humans, but that human experts improve more rapidly with
          additional time."
        </p>
        <p>
          I'm proud to say that the paper lists me as a contributor. I
          contributed by maintaining
          <a href="https://vivaria.metr.org">Vivaria</a>, the open-source
          software that METR uses to check how well AI agents (and humans)
          perform on the benchmark.
        </p>
        <p>
          I encourage you to read our
          <a
            href="https://metr.org/blog/2024-11-22-evaluating-r-d-capabilities-of-llms/"
            >blog post</a
          >
          discussing the paper, or the
          <a href="https://arxiv.org/abs/2411.15114">paper</a> itself.
        </p>
      </section>
    </article>

    <script src="https://unpkg.com/prismjs@1.21.0/components/prism-core.min.js"></script>
    <script src="https://unpkg.com/prismjs@1.21.0/plugins/autoloader/prism-autoloader.min.js"></script>
  </body>
</html>
